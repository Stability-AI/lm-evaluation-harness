# 0-shot Multilingual Results
|                                                        Model                                                        | Average | LAMBADA OpenAI (DeepL) | xCOPA | xStoryCloze | xWinograd |
| ------------------------------------------------------------------------------------------------------------------- | ------: | ---------------------: | ----: | ----------: | --------: |
| google/gemma-7b                                                                                                     |   65.84 |                  57.42 | 63.78 |       64.93 |     77.24 |
| /weka2/ckpts/stablelm_2_release/stablelm-2-12b/candidates/stablelm-2-13b-hf-cooldown-pretrain-mix-continued-step19k |   65.08 |                  60.73 | 62.82 |       61.42 |     75.37 |
| Qwen/Qwen1.5-14b                                                                                                    |   63.98 |                  57.22 | 61.49 |       61.78 |     75.44 |
| mistralai/Mistral-7B-v0.1                                                                                           |   62.91 |                  59.09 | 56.65 |       59.36 |     76.55 |

\* : Byte-length Normalized Accuracy
