{
  "results": {
    "arc_challenge_mt_es": {
      "acc": 0.3384615384615385,
      "acc_stderr": 0.013839645184134622,
      "acc_norm": 0.358974358974359,
      "acc_norm_stderr": 0.014030145004220054
    },
    "truthfulqa_mc_mt_es": {
      "mc1": 0.25602027883396705,
      "mc1_stderr": 0.015547287277856025,
      "mc2": 0.39855280908905655,
      "mc2_stderr": 0.014829756351622337
    },
    "hendrycksTest_mt_es": {
      "acc": 0.3146757679180887,
      "acc_stderr": 0.012136938632695007,
      "acc_norm": 0.3023890784982935,
      "acc_norm_stderr": 0.01200381097566003
    },
    "hellaswag_mt_es": {
      "acc": 0.5019202048218476,
      "acc_stderr": 0.005164490622086863,
      "acc_norm": 0.6494559419671432,
      "acc_norm_stderr": 0.004928410154620291
    }
  },
  "versions": {
    "arc_challenge_mt_es": 0,
    "truthfulqa_mc_mt_es": 1,
    "hendrycksTest_mt_es": 0,
    "hellaswag_mt_es": 0
  },
  "config": {
    "model": "hf-causal-experimental",
    "model_args": "pretrained=/fsx/dakota/orca/stablelm_spanish_95k_instruct_rest_hf,dtype=bfloat16,use_accelerate=True,trust_remote_code=True",
    "num_fewshot": 0,
    "batch_size": 4,
    "device": null,
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}
