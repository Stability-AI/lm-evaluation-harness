# Results
|                   Model                   | Average | ARC Challenge✱ | ARC Easy✱ | BoolQ | HellaSwag✱ | LAMBADA OpenAI | OpenBookQA | PIQA  | SciQ | Winogrande |
| ----------------------------------------- | ------: | -------------: | --------: | ----: | ---------: | -------------: | ---------: | ----: | ---: | ---------: |
| mistralai/Mistral-7B-v0.1                 |   73.00 |          54.01 |     79.50 | 83.73 |      81.10 |          75.74 |       32.4 | 80.63 | 95.9 |      73.95 |
| meta-llama/Llama-2-13b-hf                 |   71.63 |          49.23 |     77.61 | 80.52 |      79.36 |          76.77 |       35.4 | 79.05 | 94.5 |      72.22 |
| qwen/qwen-14b                             |   70.40 |          47.27 |     70.58 | 86.51 |      81.31 |          72.87 |       33.4 | 79.65 | 94.9 |      67.09 |
| meta-llama/Llama-2-7b-hf                  |   68.91 |          46.16 |     74.54 | 77.74 |      75.94 |          73.47 |       31.4 | 77.75 | 93.6 |      69.61 |
| huggyllama/llama-7b                       |   68.88 |          44.62 |     72.85 | 75.05 |      76.22 |          73.55 |       34.4 | 78.67 | 94.6 |      69.93 |
| Qwen/Qwen-7B                              |   68.09 |          49.15 |     65.19 | 74.56 |      88.85 |          69.67 |       32.2 | 73.99 | 93.2 |      65.98 |
| tiiuae/falcon-7b                          |   67.81 |          43.69 |     70.79 | 73.55 |      76.35 |          74.56 |       30.6 | 79.49 | 94.0 |      67.25 |
| Qwen/Qwen-7B-Chat                         |   67.43 |          46.67 |     64.48 | 71.68 |      84.97 |          65.48 |       35.6 | 78.73 | 90.7 |      68.59 |
| mosaicml/mpt-7b                           |   66.97 |          41.89 |     70.03 | 73.94 |      76.17 |          68.64 |       31.4 | 78.89 | 93.7 |      68.03 |
| baichuan-inc/Baichuan2-7B-Base            |   66.79 |          43.17 |     72.81 | 73.09 |      72.29 |          70.99 |       30.4 | 76.17 | 94.6 |      67.56 |
| stabilityai/stablelm-base-alpha-7b-v2     |   66.66 |          40.53 |     69.11 | 70.31 |      74.27 |          74.19 |       30.4 | 78.45 | 93.9 |      68.82 |
| stablelm-3b-4e1t                          |   66.65 |          40.02 |     67.72 | 75.63 |      73.90 |          70.64 |       31.4 | 79.22 | 94.8 |      66.54 |
| openlm-research/open_llama_7b_v2          |   66.46 |          42.41 |     69.65 | 71.41 |      74.65 |          71.05 |       30.2 | 79.16 | 93.8 |      65.82 |
| microsoft/phi-1_5                         |   65.64 |          48.04 |     73.15 | 74.53 |      62.62 |          52.75 |       37.6 | 76.33 | 93.2 |      72.53 |
| EleutherAI/gpt-neox-20B                   |   65.42 |          40.78 |     68.69 | 69.48 |      71.43 |          71.98 |       29.8 | 77.42 | 93.1 |      66.14 |
| togethercomputer/RedPajama-INCITE-7B-Base |   64.91 |          39.42 |     69.19 | 70.76 |      70.33 |          71.34 |       29.0 | 77.15 | 92.7 |      64.33 |
| cerebras/btlm-3b-8k-base                  |   63.52 |          37.63 |     67.09 | 69.63 |      69.78 |          66.23 |       27.6 | 75.84 | 92.9 |      64.96 |
| EleutherAI/pythia-12b                     |   62.33 |          35.07 |     63.72 | 67.31 |      67.38 |          70.64 |       26.4 | 76.28 | 90.2 |      64.01 |
| openlm-research/open_llama_3b_v2          |   62.22 |          36.09 |     63.51 | 65.69 |      69.99 |          66.74 |       26.0 | 76.66 | 92.4 |      62.90 |
| stabilityai/stablelm-base-alpha-3b-v2     |   62.04 |          35.07 |     63.26 | 64.56 |      68.58 |          70.25 |       26.4 | 76.01 | 92.1 |      62.12 |
| facebook/opt-6.7b                         |   61.69 |          34.81 |     60.14 | 66.02 |      67.20 |          67.65 |       27.6 | 76.33 | 90.1 |      65.35 |
| EleutherAI/pythia-6.9b                    |   60.29 |          35.32 |     61.07 | 64.01 |      63.88 |          67.01 |       25.8 | 75.08 | 89.8 |      60.62 |
| bigscience/bloom-7b1                      |   58.47 |          33.53 |     57.37 | 62.84 |      62.29 |          57.56 |       25.2 | 72.74 | 90.1 |      64.64 |
| EleutherAI/pythia-2.8b-deduped            |   58.34 |          32.94 |     59.09 | 64.13 |      59.44 |          65.15 |       23.8 | 74.10 | 88.2 |      58.25 |
| facebook/opt-2.7b                         |   57.31 |          31.31 |     54.29 | 60.34 |      60.60 |          63.57 |       25.0 | 73.83 | 85.8 |      61.01 |
| bigscience/bloom-3b                       |   54.62 |          30.38 |     53.28 | 61.71 |      54.53 |          51.74 |       21.8 | 70.57 | 89.1 |      58.48 |
| stabilityai/stablelm-base-alpha-7b        |   49.63 |          27.05 |     44.87 | 60.06 |      41.22 |          55.11 |       21.4 | 66.76 | 80.1 |      50.12 |
| stabilityai/stablelm-base-alpha-3b        |   45.63 |          25.77 |     42.05 | 57.65 |      38.31 |          41.72 |       17.0 | 63.82 | 71.7 |      52.64 |
