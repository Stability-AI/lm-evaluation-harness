# Results
|                           Model                           | ARC Challenge✱ | ARC Easy✱ | BoolQ | HellaSwag✱ | LAMBADA OpenAI | OpenBookQA | PIQA  | SciQ | SocialIQA | Winogrande | Average |
| --------------------------------------------------------- | -------------: | --------: | ----: | ---------: | -------------: | ---------: | ----: | ---: | --------: | ---------: | ------: |
| meta-llama/Llama-2-13b-hf                                 |          49.23 |     77.61 | 80.52 |      79.36 |          76.77 |       35.4 | 79.05 | 94.5 |     42.78 |      72.22 |   68.74 |
| /fsx/shared/codeai/hf_13b_trained_folder/hf_llama_13b_20k |          48.46 |     76.01 | 79.48 |      78.34 |          76.11 |       32.4 | 77.91 | 94.4 |     43.19 |      73.09 |   67.94 |
| huggyllama/llama-7b                                       |          44.62 |     72.85 | 75.05 |      76.22 |          73.55 |       34.4 | 78.67 | 94.6 |     44.83 |      69.93 |   66.47 |
| meta-llama/Llama-2-7b-hf                                  |          46.16 |     74.54 | 77.74 |      75.94 |          73.47 |       31.4 | 77.75 | 93.6 |     43.50 |      69.61 |   66.37 |
| Qwen/Qwen-7B                                              |          49.15 |     65.19 | 74.56 |      88.85 |          69.67 |       32.2 | 73.99 | 93.2 |     49.44 |      65.98 |   66.22 |
| Qwen/Qwen-7B-Chat                                         |          46.67 |     64.48 | 71.68 |      84.97 |          65.48 |       35.6 | 78.73 | 90.7 |     47.03 |      68.59 |   65.39 |
| mosaicml/mpt-7b                                           |          41.89 |     70.03 | 73.94 |      76.17 |          68.64 |       31.4 | 78.89 | 93.7 |     45.14 |      68.03 |   64.78 |
| microsoft/phi-1_5                                         |          48.04 |     73.15 | 74.53 |      62.62 |          52.75 |       37.6 | 76.33 | 93.2 |     55.37 |      72.53 |   64.61 |
| stabilityai/stablelm-base-alpha-7b-v2                     |          40.53 |     69.11 | 70.31 |      74.27 |          74.19 |       30.4 | 78.45 | 93.9 |     42.43 |      68.82 |   64.24 |
| openlm-research/open_llama_7b_v2                          |          42.41 |     69.65 | 71.41 |      74.65 |          71.05 |       30.2 | 79.16 | 93.8 |     41.97 |      65.82 |   64.01 |
| togethercomputer/RedPajama-INCITE-7B-Base                 |          39.42 |     69.19 | 70.76 |      70.33 |          71.34 |       29.0 | 77.15 | 92.7 |     42.58 |      64.33 |   62.68 |
| cerebras/btlm-3b-8k-base                                  |          37.63 |     67.09 | 69.63 |      69.78 |          66.23 |       27.6 | 75.84 | 92.9 |     42.78 |      64.96 |   61.44 |
| EleutherAI/pythia-12b                                     |          35.07 |     63.72 | 67.31 |      67.38 |          70.64 |       26.4 | 76.28 | 90.2 |     42.02 |      64.01 |   60.30 |
| openlm-research/open_llama_3b_v2                          |          36.09 |     63.51 | 65.69 |      69.99 |          66.74 |       26.0 | 76.66 | 92.4 |     41.20 |      62.90 |   60.12 |
| stabilityai/stablelm-base-alpha-3b-v2                     |          35.07 |     63.26 | 64.56 |      68.58 |          70.25 |       26.4 | 76.01 | 92.1 |     42.48 |      62.12 |   60.08 |
| facebook/opt-6.7b                                         |          34.81 |     60.14 | 66.02 |      67.20 |          67.65 |       27.6 | 76.33 | 90.1 |     42.63 |      65.35 |   59.78 |
| bigscience/bloom-7b1                                      |          33.53 |     57.37 | 62.84 |      62.29 |          57.56 |       25.2 | 72.74 | 90.1 |     42.12 |      64.64 |   56.84 |
| EleutherAI/pythia-2.8b-deduped                            |          32.94 |     59.09 | 64.13 |      59.44 |          65.15 |       23.8 | 74.10 | 88.2 |     40.94 |      58.25 |   56.60 |
| facebook/opt-2.7b                                         |          31.31 |     54.29 | 60.34 |      60.60 |          63.57 |       25.0 | 73.83 | 85.8 |     40.84 |      61.01 |   55.66 |
| bigscience/bloom-3b                                       |          30.38 |     53.28 | 61.71 |      54.53 |          51.74 |       21.8 | 70.57 | 89.1 |     40.17 |      58.48 |   53.18 |
| stabilityai/stablelm-base-alpha-7b                        |          27.05 |     44.87 | 60.06 |      41.22 |          55.11 |       21.4 | 66.76 | 80.1 |     39.46 |      50.12 |   48.61 |
| stabilityai/stablelm-base-alpha-3b                        |          25.77 |     42.05 | 57.65 |      38.31 |          41.72 |       17.0 | 63.82 | 71.7 |     35.62 |      52.64 |   44.63 |
